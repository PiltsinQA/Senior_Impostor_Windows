—Å–¥–µ–ª–∞–π —á—Ç–æ –±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –≤–∫–ª—é—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –∏–∑ —Ñ—É–Ω–∫—Ü–∏–π —Å –∑–≤—É–∫–æ–º –ª–∏–±–æ –∞–≤—Ç–æ –ª–∏–±–æ —Ä—É—á–Ω–æ–µ

—Ç–∞–∫ –∂–µ –¥–æ–±–∞–≤—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Ç–æ–∫–µ–Ω–∞ –æ—Ç –≥–∏–≥–∞—á–∞—Ç–∞

–∫–∞–∫ —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –µ–≥–æ –≤–≤–æ–¥–∏—Ç –∏ –Ω–∞–∂–∏–º–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∏ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ —Ç–æ –∂–µ –µ—Å—Ç—å

—Ç–∞–∫ –∂–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ —Å—Ç–æ–ø - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—É—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º

–∫–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ - –æ—á–∏—â–∞–µ—Ç –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è



–≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–µ —Ç—Ä–æ–≥–∞–π –∏ –Ω–µ —É–¥–∞–ª—è–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª

–ø—Ä–∏—à–ª–∏ –∫–æ–¥ –ø–æ–ª–Ω–æ—Å—Ç—å—é





import sys

import threading

import sounddevice as sd

import numpy as np

import base64

import pyperclip

import json

import os

from io import BytesIO

from PIL import ImageGrab

from faster_whisper import WhisperModel

from gigachat import GigaChat

from PyQt6.QtWidgets import (QApplication, QLabel, QMainWindow, QTabWidget,

                             QWidget, QVBoxLayout, QHBoxLayout, QTextEdit,

                             QLineEdit, QPushButton, QSlider)

from PyQt6.QtCore import Qt, QTimer



CONFIG_FILE = "settings_win.json"

DEFAULT_PROMPT = "–¢—ã ‚Äî Senior QA –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫. –†–µ—à–∞–π –∑–∞–¥–∞—á–∏ –ø–æ—à–∞–≥–æ–≤–æ, –æ—Ç–≤–µ—á–∞–π —á–µ—Ç–∫–æ."



sd.default.latency = 'low'

sd.default.blocksize = 1024



class InterviewAssistantWin(QMainWindow):

    def __init__(self):

        super().__init__()

        self.setWindowTitle("Interview Assistant")

        self.resize(450, 650)



        # ------------------ FLAGS ------------------

        self.is_recording = False

        self.auto_mode = False

        self.stop_flag = False

        self.audio_frames = []

        self.fs = 16000

        self.history = []

        self.history_index = -1

        self.whisper_model = None

        self.current_whisper_size = ""



        # ------------------ TIMERS ------------------

        self.auto_timer = QTimer()

        self.auto_timer.timeout.connect(self.auto_process_cycle)

        self.countdown_timer = QTimer()

        self.countdown_timer.timeout.connect(self.update_countdown)

        self.auto_seconds_left = 0



        # ------------------ UI ------------------

        self.init_ui()

        self.load_settings()



    # ================= UI =================

    def init_ui(self):

        self.tabs = QTabWidget(self)

        self.setCentralWidget(self.tabs)



        # --- Chat Tab ---

        self.tab_chat = QWidget()

        layout = QVBoxLayout()



        self.status_indicator = QLabel("‚ö™ –ì–û–¢–û–í")

        self.nav_label = QLabel("0 / 0")



        top_bar = QHBoxLayout()

        top_bar.addWidget(self.status_indicator)

        top_bar.addStretch()

        top_bar.addWidget(self.nav_label)

        layout.addLayout(top_bar)



        self.label = QTextEdit()

        self.label.setReadOnly(True)

        layout.addWidget(self.label)



        self.log_output = QTextEdit()

        self.log_output.setReadOnly(True)

        self.log_output.setFixedHeight(80)

        layout.addWidget(self.log_output)



        ctrl_layout = QHBoxLayout()

        self.btn_mic = QPushButton("üéô –ú–ò–ö–†–û–§–û–ù")

        self.btn_mic.setCheckable(True)

        self.btn_mic.clicked.connect(self.toggle_mic)

        ctrl_layout.addWidget(self.btn_mic)



        self.btn_auto = QPushButton("ü§ñ –ê–í–¢–û")

        self.btn_auto.setCheckable(True)

        self.btn_auto.clicked.connect(self.toggle_auto_mode)

        ctrl_layout.addWidget(self.btn_auto)



        btn_scr = QPushButton("üì∏ SCREEN")

        btn_scr.clicked.connect(self.take_screenshot)

        ctrl_layout.addWidget(btn_scr)



        layout.addLayout(ctrl_layout)



        bottom_layout = QHBoxLayout()

        self.input_field = QLineEdit()

        self.input_field.setPlaceholderText("–í–æ–ø—Ä–æ—Å –≤—Ä—É—á–Ω—É—é...")

        self.input_field.returnPressed.connect(self.send_manual_text)

        bottom_layout.addWidget(self.input_field)



        btn_clear = QPushButton("üóë –û—á–∏—Å—Ç–∏—Ç—å")

        btn_clear.clicked.connect(self.clear_history)

        bottom_layout.addWidget(btn_clear)



        btn_stop = QPushButton("‚èπ –°–¢–û–ü")

        btn_stop.clicked.connect(self.stop_current_process)

        bottom_layout.addWidget(btn_stop)



        layout.addLayout(bottom_layout)



        self.tab_chat.setLayout(layout)

        self.tabs.addTab(self.tab_chat, "–ß–∞—Ç")



        # --- Settings Tab ---

        self.tab_settings = QWidget()

        s_layout = QVBoxLayout()



        s_layout.addWidget(QLabel("<b>GIGACHAT TOKEN</b>"))

        self.giga_token_input = QLineEdit()

        s_layout.addWidget(self.giga_token_input)



        self.whisper_name_input = QLineEdit()

        self.whisper_name_input.setPlaceholderText("base, tiny, small...")

        s_layout.addWidget(QLabel("Whisper Model:"))

        s_layout.addWidget(self.whisper_name_input)



        s_layout.addWidget(QLabel("System Prompt:"))

        self.prompt_edit = QTextEdit()

        s_layout.addWidget(self.prompt_edit)



        self.btn_save = QPushButton("üíæ –°–û–•–†–ê–ù–ò–¢–¨ –ù–ê–°–¢–†–û–ô–ö–ò")

        self.btn_save.clicked.connect(self.save_settings)

        s_layout.addWidget(self.btn_save)



        self.tab_settings.setLayout(s_layout)

        self.tabs.addTab(self.tab_settings, "‚öôÔ∏è")



    # ================= Settings =================

    def save_settings(self):

        data = {

            "prompt": self.prompt_edit.toPlainText(),

            "giga_token": self.giga_token_input.text().strip(),

            "whisper_model": self.whisper_name_input.text().strip()

        }

        with open(CONFIG_FILE, "w", encoding="utf-8") as f:

            json.dump(data, f, ensure_ascii=False, indent=4)

        self.add_log("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")



    def load_settings(self):

        if os.path.exists(CONFIG_FILE):

            with open(CONFIG_FILE, "r", encoding="utf-8") as f:

                data = json.load(f)

                self.prompt_edit.setText(data.get("prompt", DEFAULT_PROMPT))

                self.giga_token_input.setText(data.get("giga_token", ""))

                self.whisper_name_input.setText(data.get("whisper_model", "base"))



    # ================= Log =================

    def add_log(self, message):

        self.log_output.append(message)

        self.log_output.verticalScrollBar().setValue(self.log_output.verticalScrollBar().maximum())



    # ================= WHISPER =================

    def get_whisper(self):

        model_name = self.whisper_name_input.text().strip() or "base"

        if self.whisper_model is None or self.current_whisper_size != model_name:

            self.add_log(f"‚åõ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper {model_name}...")

            self.whisper_model = WhisperModel(model_name, device="cpu", compute_type="int8")

            self.current_whisper_size = model_name

        return self.whisper_model



    # ================= AUDIO =================

    def toggle_mic(self):

        if self.auto_mode:

            self.btn_auto.setChecked(False)

            self.auto_mode = False

            self.auto_timer.stop()

            self.countdown_timer.stop()

            self.add_log("‚ö†Ô∏è Auto –æ—Ç–∫–ª—é—á–µ–Ω, —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω")



        if not self.is_recording:

            self.audio_frames = []

            self.is_recording = True

            self.stop_flag = False

            self.status_indicator.setText("üî¥ –ó–ê–ü–ò–°–¨")

            threading.Thread(target=self.record_loop, daemon=True).start()

        else:

            self.is_recording = False

            self.status_indicator.setText("‚åõ –û–±—Ä–∞–±–æ—Ç–∫–∞...")

            threading.Thread(target=self.process_audio_manual, daemon=True).start()



    def toggle_auto_mode(self):

        if self.is_recording:

            self.btn_mic.setChecked(False)

            self.is_recording = False

            self.add_log("‚ö†Ô∏è –ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω, —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å Auto")



        self.auto_mode = self.btn_auto.isChecked()

        if self.auto_mode:

            self.audio_frames = []

            self.stop_flag = False

            self.auto_seconds_left = 15

            self.status_indicator.setText("‚ñ∂Ô∏è Auto –≤–∫–ª—é—á–µ–Ω")

            threading.Thread(target=self.record_loop, daemon=True).start()

            self.auto_timer.start(15000)

            self.countdown_timer.start(1000)

        else:

            self.auto_timer.stop()

            self.countdown_timer.stop()

            self.status_indicator.setText("‚ö™ –ì–û–¢–û–í")



    def update_countdown(self):

        if self.auto_mode:

            self.auto_seconds_left -= 1

            if self.auto_seconds_left >= 0:

                self.btn_auto.setText(f"ü§ñ –ê–í–¢–û: {self.auto_seconds_left}s")



    def auto_process_cycle(self):

        self.auto_seconds_left = 15

        if self.audio_frames:

            frames = list(self.audio_frames)

            self.audio_frames = []

            threading.Thread(target=self.process_audio_silent, args=(frames,), daemon=True).start()



    def record_loop(self):

        try:

            def audio_callback(indata, frames, time_info, status):

                if self.stop_flag:

                    raise sd.CallbackStop()

                if self.is_recording or self.auto_mode:

                    self.audio_frames.append(indata.copy())



            with sd.InputStream(samplerate=self.fs, channels=1, dtype="float32", blocksize=1024,

                                callback=audio_callback):

                while (self.is_recording or self.auto_mode) and not self.stop_flag:

                    sd.sleep(50)

        except Exception as e:

            self.add_log(f"‚ùå Audio Error: {e}")



    def process_audio_manual(self):

        if self.audio_frames:

            frames = np.concatenate(self.audio_frames).flatten()

            model = self.get_whisper()

            segments, _ = model.transcribe(frames, language="ru")

            text = " ".join([s.text for s in segments]).strip()

            if text:

                self.add_log(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")

                self.ask_giga(text)

        self.status_indicator.setText("‚ö™ –ì–û–¢–û–í")

        self.btn_mic.setChecked(False)



    def process_audio_silent(self, frames):

        try:

            audio_data = np.concatenate(frames).flatten()

            model = self.get_whisper()

            segments, _ = model.transcribe(audio_data, language="ru")

            text = " ".join([s.text for s in segments]).strip()

            if text and not self.stop_flag:

                self.add_log(f"‚úÖ Auto –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text[:30]}...")

                self.ask_giga(text)

        except Exception as e:

            self.add_log(f"‚ùå Whisper Auto Error: {e}")



    # ================= GIGACHAT =================

    def ask_giga(self, text, image_b64=None):

        if self.stop_flag: return

        token = self.giga_token_input.text().strip()

        if not token: return

        try:

            with GigaChat(credentials=token, verify_ssl_certs=False) as giga:

                attachments = []

                if image_b64:

                    uploaded = giga.upload_file(("t.jpg", base64.b64decode(image_b64), "image/jpeg"))

                    f_id = getattr(uploaded, 'id_', getattr(uploaded, 'file_id', None))

                    if f_id:

                        attachments = [f_id]



                res = giga.chat({"model": "GigaChat-Max", "messages": [

                    {"role": "system", "content": self.prompt_edit.toPlainText()},

                    {"role": "user", "content": text, "attachments": attachments}

                ]})

                answer = res.choices[0].message.content

                self.history.append(answer)

                self.history_index = len(self.history) - 1

                self.display_history_item()

        except Exception as e:

            self.add_log(f"‚ùå GigaChat Error")



    def display_history_item(self):

        if self.history_index != -1:

            item = self.history[self.history_index]

            self.label.setHtml(item.replace('\n', '<br>'))

            pyperclip.copy(item)

            self.nav_label.setText(f"{self.history_index + 1} / {len(self.history)}")



    # ================= Utils =================

    def take_screenshot(self):

        try:

            screenshot = ImageGrab.grab()

            buf = BytesIO()

            screenshot.save(buf, format="JPEG")

            threading.Thread(target=self.ask_giga,

                             args=("–†–µ—à–∏ –∑–∞–¥–∞—á—É.", base64.b64encode(buf.getvalue()).decode('utf-8')),

                             daemon=True).start()

        except:

            pass



    def clear_history(self):

        self.history = []

        self.history_index = -1

        self.label.clear()

        self.nav_label.setText("0 / 0")

        self.add_log("üóë –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞")



    def stop_current_process(self):

        self.stop_flag = True

        self.is_recording = False

        self.auto_mode = False

        self.status_indicator.setText("‚èπ –°–¢–û–ü")

        self.btn_mic.setChecked(False)

        self.btn_auto.setChecked(False)

        self.add_log("‚èπ –ü—Ä–æ—Ü–µ—Å—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")



    def send_manual_text(self):

        t = self.input_field.text()

        if t:

            self.input_field.clear()

            threading.Thread(target=self.ask_giga, args=(t,), daemon=True).start()





if __name__ == "__main__":

    app = QApplication(sys.argv)

    win = InterviewAssistantWin()

    win.show()

    sys.exit(app.exec())