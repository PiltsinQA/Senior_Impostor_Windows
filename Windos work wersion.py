import sys
import threading
import json
import os
import requests
import base64
import ctypes
import re
import numpy as np
import pyaudiowpatch as pyaudio
import pyperclip
from io import BytesIO
from PIL import ImageGrab
from faster_whisper import WhisperModel

from PyQt6.QtWidgets import (QApplication, QLabel, QMainWindow, QTabWidget,
                             QWidget, QVBoxLayout, QHBoxLayout, QTextEdit,
                             QLineEdit, QPushButton, QProgressBar)
from PyQt6.QtCore import QTimer, pyqtSignal, QObject, Qt
from PyQt6.QtGui import QKeyEvent

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è Stealth-—Ä–µ–∂–∏–º–∞
WDA_EXCLUDEFROMCAPTURE = 0x00000011
CONFIG_FILE = "settings_win.json"
DEFAULT_PROMPT = "–¢—ã ‚Äî Senior QA. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ —á–µ—Ç–∫–æ."


# ================= SAFE QT SIGNALS =================
class SafeSignals(QObject):
    log = pyqtSignal(str)
    text = pyqtSignal(str)
    status = pyqtSignal(str)
    btn_auto_text = pyqtSignal(str)
    volume = pyqtSignal(int)  # –°–∏–≥–Ω–∞–ª –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —É—Ä–æ–≤–Ω—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ (0-100)


# ================= MAIN WINDOW =================
class InterviewAssistantWin(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Stealth Assistant PRO v5.2")
        self.resize(460, 800)

        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowStaysOnTopHint)
        self.setFocusPolicy(Qt.FocusPolicy.StrongFocus)  # –û–∫–Ω–æ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∞—Ç—å —Ñ–æ–∫—É—Å

        self.signals = SafeSignals()
        self.signals.log.connect(self._add_log)
        self.signals.text.connect(self._add_to_history)
        self.signals.status.connect(self._set_status)
        self.signals.btn_auto_text.connect(self._set_btn_auto_text)
        self.signals.volume.connect(self._update_volume)

        # –°–æ—Å—Ç–æ—è–Ω–∏—è
        self.is_running = False
        self.auto_mode = False
        self.mic_mode = False
        self.whisper_model = None
        self.accumulated_text = ""

        # –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
        self.history = []
        self.history_index = -1

        self.auto_timer = QTimer()
        self.auto_timer.timeout.connect(self.trigger_ai_send)
        self.countdown_timer = QTimer()
        self.countdown_timer.timeout.connect(self.update_countdown)
        self.auto_seconds_left = 0

        self.init_ui()
        self.load_settings()
        self.update_button_styles()  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∏–ª–µ–π –∫–Ω–æ–ø–æ–∫

        QTimer.singleShot(500, self.apply_hard_stealth)

    def apply_hard_stealth(self):
        try:
            hwnd = int(self.winId())
            ctypes.windll.user32.SetWindowDisplayAffinity(hwnd, WDA_EXCLUDEFROMCAPTURE)
            self.signals.log.emit("üõ° STEALTH: –ê–ö–¢–ò–í–ò–†–û–í–ê–ù")
        except:
            self.signals.log.emit("‚ùå STEALTH: –û—à–∏–±–∫–∞")

    # ---------------- UI ----------------
    def init_ui(self):
        tabs = QTabWidget(self)
        self.setCentralWidget(tabs)

        chat = QWidget()
        layout = QVBoxLayout()

        self.status_label = QLabel("‚ö™ –ì–û–¢–û–í")
        layout.addWidget(self.status_label)

        # –ü–æ–ª–µ –≤—ã–≤–æ–¥–∞ –æ—Ç–≤–µ—Ç–∞ AI
        self.output = QTextEdit()
        self.output.setReadOnly(True)
        self.output.setPlaceholderText("–ó–¥–µ—Å—å –ø–æ—è–≤—è—Ç—Å—è –æ—Ç–≤–µ—Ç—ã AI. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Ç—Ä–µ–ª–∫–∏ ‚Üê ‚Üí –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏.")
        layout.addWidget(self.output)

        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –∏—Å—Ç–æ—Ä–∏–∏ (–Ω–æ–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è)
        self.history_label = QLabel("–ò—Å—Ç–æ—Ä–∏—è: 0/0")
        self.history_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(self.history_label)

        # –í–∏–∑—É–∞–ª—å–Ω–∞—è —à–∫–∞–ª–∞ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        vol_layout = QHBoxLayout()
        vol_layout.addWidget(QLabel("üé§"))
        self.volume_bar = QProgressBar()
        self.volume_bar.setRange(0, 100)
        self.volume_bar.setTextVisible(False)
        self.volume_bar.setFixedHeight(10)
        self.volume_bar.setStyleSheet("""
            QProgressBar { border: 1px solid grey; border-radius: 5px; background: #222; }
            QProgressBar::chunk { background-color: #00ff00; width: 2px; }
        """)
        vol_layout.addWidget(self.volume_bar)
        layout.addLayout(vol_layout)

        self.log_widget = QTextEdit()
        self.log_widget.setReadOnly(True)
        self.log_widget.setFixedHeight(80)
        self.log_widget.setStyleSheet(
            "background: #1e1e1e; color: #00ff00; font-family: 'Courier New'; font-size: 10px;")
        layout.addWidget(self.log_widget)

        # –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ (–ö–Ω–æ–ø–∫–∏ V)
        nav_row = QHBoxLayout()
        self.btn_prev = QPushButton("‚óÄ –ü—Ä–µ–¥ (‚Üê)")
        self.btn_prev.clicked.connect(self.prev_message)
        self.btn_prev.setFocusPolicy(Qt.FocusPolicy.ClickFocus)  # –ù–µ –ø–æ–ª—É—á–∞–µ—Ç —Ñ–æ–∫—É—Å –æ—Ç —Å—Ç—Ä–µ–ª–æ–∫
        self.btn_next = QPushButton("–°–ª–µ–¥ (‚Üí) ‚ñ∂")
        self.btn_next.clicked.connect(self.next_message)
        self.btn_next.setFocusPolicy(Qt.FocusPolicy.ClickFocus)  # –ù–µ –ø–æ–ª—É—á–∞–µ—Ç —Ñ–æ–∫—É—Å –æ—Ç —Å—Ç—Ä–µ–ª–æ–∫
        nav_row.addWidget(self.btn_prev)
        nav_row.addWidget(self.btn_next)
        layout.addLayout(nav_row)

        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        row = QHBoxLayout()
        self.btn_mic = QPushButton("üéô –ú–ò–ö")
        self.btn_mic.setCheckable(True)
        self.btn_mic.setFixedHeight(40)
        self.btn_mic.clicked.connect(self.toggle_mic_mode)
        self.btn_mic.setFocusPolicy(Qt.FocusPolicy.ClickFocus)  # –ù–µ –ø–æ–ª—É—á–∞–µ—Ç —Ñ–æ–∫—É—Å –æ—Ç —Å—Ç—Ä–µ–ª–æ–∫
        row.addWidget(self.btn_mic)

        self.btn_auto = QPushButton("ü§ñ –ê–í–¢–û")
        self.btn_auto.setCheckable(True)
        self.btn_auto.setFixedHeight(40)
        self.btn_auto.clicked.connect(self.toggle_auto_mode)
        self.btn_auto.setFocusPolicy(Qt.FocusPolicy.ClickFocus)  # –ù–µ –ø–æ–ª—É—á–∞–µ—Ç —Ñ–æ–∫—É—Å –æ—Ç —Å—Ç—Ä–µ–ª–æ–∫
        row.addWidget(self.btn_auto)

        btn_scr = QPushButton("üì∏ SCR")
        btn_scr.setFixedHeight(40)
        btn_scr.clicked.connect(self.take_screenshot)
        btn_scr.setFocusPolicy(Qt.FocusPolicy.ClickFocus)  # –ù–µ –ø–æ–ª—É—á–∞–µ—Ç —Ñ–æ–∫—É—Å –æ—Ç —Å—Ç—Ä–µ–ª–æ–∫
        row.addWidget(btn_scr)
        layout.addLayout(row)

        self.input = QLineEdit()
        self.input.setPlaceholderText("–¢–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é...")
        self.input.returnPressed.connect(self.send_manual_text)
        layout.addWidget(self.input)

        chat.setLayout(layout)
        tabs.addTab(chat, "–ß–∞—Ç")

        # –í–∫–ª–∞–¥–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        settings = QWidget()
        s_layout = QVBoxLayout()
        s_layout.addWidget(QLabel("API Key (OpenRouter)"))
        self.token_input = QLineEdit()
        s_layout.addWidget(self.token_input)

        s_layout.addWidget(QLabel("Whisper Model (tiny/base/small)"))
        self.whisper_input = QLineEdit("base")
        s_layout.addWidget(self.whisper_input)

        s_layout.addWidget(QLabel("–ò–Ω—Ç–µ—Ä–≤–∞–ª –ê–í–¢–û (—Å–µ–∫)"))
        self.auto_interval_input = QLineEdit("15")
        s_layout.addWidget(self.auto_interval_input)

        self.prompt_edit = QTextEdit(DEFAULT_PROMPT)
        s_layout.addWidget(QLabel("–ü—Ä–æ–º–ø—Ç"))
        s_layout.addWidget(self.prompt_edit)

        btn_save = QPushButton("üíæ –°–û–•–†–ê–ù–ò–¢–¨")
        btn_save.clicked.connect(self.save_settings)
        btn_save.setFocusPolicy(Qt.FocusPolicy.ClickFocus)
        s_layout.addWidget(btn_save)
        settings.setLayout(s_layout)
        tabs.addTab(settings, "‚öôÔ∏è")

    # ---------------- –°–¢–ò–õ–ò –ö–ù–û–ü–û–ö ----------------
    def update_button_styles(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ü–≤–µ—Ç–∞ –∫–Ω–æ–ø–æ–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        # –°—Ç–∏–ª—å –¥–ª—è –ú–ò–ö
        if self.mic_mode and self.is_running:
            self.btn_mic.setStyleSheet("""
                QPushButton {
                    background-color: #e74c3c;
                    color: white;
                    font-weight: bold;
                    border: 2px solid #c0392b;
                }
                QPushButton:hover {
                    background-color: #c0392b;
                }
            """)
        else:
            self.btn_mic.setStyleSheet("""
                QPushButton {
                    background-color: #2980b9;
                    color: white;
                    border: 1px solid #3498db;
                }
                QPushButton:hover {
                    background-color: #3498db;
                }
            """)

        # –°—Ç–∏–ª—å –¥–ª—è –ê–í–¢–û
        if self.auto_mode and self.is_running:
            self.btn_auto.setStyleSheet("""
                QPushButton {
                    background-color: #27ae60;
                    color: white;
                    font-weight: bold;
                    border: 2px solid #219653;
                }
                QPushButton:hover {
                    background-color: #219653;
                }
            """)
        else:
            self.btn_auto.setStyleSheet("""
                QPushButton {
                    background-color: #7f8c8d;
                    color: white;
                    border: 1px solid #95a5a6;
                }
                QPushButton:hover {
                    background-color: #95a5a6;
                }
            """)

    # ---------------- –õ–û–ì–ò–ö–ê –ò–°–¢–û–†–ò–ò ----------------
    def _add_to_history(self, text):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –µ–≥–æ"""
        self.history.append(text)
        self.history_index = len(self.history) - 1
        self._display_current_message()

    def _display_current_message(self):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ —Ç–µ–∫—É—â–µ–º—É –∏–Ω–¥–µ–∫—Å—É"""
        if 0 <= self.history_index < len(self.history):
            msg = self.history[self.history_index]
            self.output.setHtml(msg.replace("\n", "<br>"))
            pyperclip.copy(msg)
            self.history_label.setText(f"–ò—Å—Ç–æ—Ä–∏—è: {self.history_index + 1}/{len(self.history)}")
        else:
            self.output.clear()
            self.history_label.setText("–ò—Å—Ç–æ—Ä–∏—è: 0/0")

    def prev_message(self):
        if self.history_index > 0:
            self.history_index -= 1
            self._display_current_message()

    def next_message(self):
        if self.history_index < len(self.history) - 1:
            self.history_index += 1
            self._display_current_message()

    def keyPressEvent(self, event):
        """–ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–µ–ª–æ–∫ ‚Üê/‚Üí –∫–∞–∫ –≥–æ—Ä—è—á–∏—Ö –∫–ª–∞–≤–∏—à –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏"""
        # –°—Ç—Ä–µ–ª–∫–∏ ‚Üê/‚Üí —Ä–∞–±–æ—Ç–∞—é—Ç –∫–∞–∫ –≥–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏ –í–°–ï–ì–î–ê, –∫—Ä–æ–º–µ –ø–æ–ª—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        if event.key() in (Qt.Key.Key_Left, Qt.Key.Key_Right):
            focused_widget = QApplication.focusWidget()

            # –ï—Å–ª–∏ —Ñ–æ–∫—É—Å –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
            if isinstance(focused_widget, QLineEdit):
                super().keyPressEvent(event)
                return

            # –î–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ ‚Äî –Ω–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –∏—Å—Ç–æ—Ä–∏–∏
            if event.key() == Qt.Key.Key_Left:
                self.prev_message()
                event.accept()
                return
            elif event.key() == Qt.Key.Key_Right:
                self.next_message()
                event.accept()
                return

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∫–ª–∞–≤–∏—à
        super().keyPressEvent(event)

    # ---------------- –ì–†–û–ú–ö–û–°–¢–¨ ----------------
    def _update_volume(self, val):
        self.volume_bar.setValue(val)

    # ---------------- –û–°–¢–ê–õ–¨–ù–ê–Ø –õ–û–ì–ò–ö–ê ----------------
    def _add_log(self, t):
        self.log_widget.append(t)

    def _set_status(self, t):
        self.status_label.setText(t)

    def _set_btn_auto_text(self, t):
        self.btn_auto.setText(t)

    def save_settings(self):
        data = {"token": self.token_input.text(), "prompt": self.prompt_edit.toPlainText(),
                "whisper": self.whisper_input.text(), "auto_interval": self.auto_interval_input.text()}
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False)
        self.signals.log.emit("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

    def load_settings(self):
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                d = json.load(f)
                self.token_input.setText(d.get("token", ""))
                self.prompt_edit.setText(d.get("prompt", DEFAULT_PROMPT))
                self.whisper_input.setText(d.get("whisper", "base"))
                self.auto_interval_input.setText(d.get("auto_interval", "15"))

    def filter_text(self, text):
        text = re.sub(r'(\w+)(?:-\1)+', r'\1', text, flags=re.IGNORECASE)
        if any(g in text.lower() for g in ["—Å—É–±—Ç–∏—Ç—Ä—ã", "—Ä–µ–¥–∞–∫—Ç–æ—Ä", "–º—É–∑—ã–∫–∞"]) or len(text.strip()) < 2:
            return ""
        return text.strip()

    def toggle_mic_mode(self):
        if self.btn_mic.isChecked():
            if self.auto_mode:
                self.toggle_auto_mode()
            self.mic_mode = True
            self.is_running = True
            self.accumulated_text = ""
            self.signals.status.emit("üî¥ –ó–ê–ü–ò–°–¨ –ú–ò–ö–†–û–§–û–ù–ê")
            self.update_button_styles()  # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∏–ª—å –∫–Ω–æ–ø–∫–∏
            threading.Thread(target=self.audio_engine, args=(True,), daemon=True).start()
        else:
            self.is_running = False
            self.mic_mode = False
            self.signals.status.emit("‚åõ –û–ë–†–ê–ë–û–¢–ö–ê...")
            self.update_button_styles()  # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∏–ª—å –∫–Ω–æ–ø–∫–∏
            self.signals.volume.emit(0)
            QTimer.singleShot(500, self.trigger_ai_send)

    def toggle_auto_mode(self):
        if self.btn_auto.isChecked():
            if self.mic_mode:
                self.btn_mic.setChecked(False)
                self.toggle_mic_mode()
            try:
                interval = int(self.auto_interval_input.text())
            except:
                interval = 15
            self.auto_mode = True
            self.is_running = True
            self.accumulated_text = ""
            self.auto_seconds_left = interval
            self.signals.status.emit("‚ñ∂Ô∏è –ê–í–¢–û-–°–õ–£–®–ê–ù–ò–ï")
            self.update_button_styles()  # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∏–ª—å –∫–Ω–æ–ø–∫–∏
            threading.Thread(target=self.audio_engine, args=(False,), daemon=True).start()
            self.auto_timer.start(interval * 1000)
            self.countdown_timer.start(1000)
            self.update_countdown()  # –°—Ä–∞–∑—É –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏
        else:
            self.stop_all_audio()
            self.update_button_styles()  # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∏–ª—å –∫–Ω–æ–ø–∫–∏

    def stop_all_audio(self):
        self.is_running = False
        self.auto_mode = False
        self.auto_timer.stop()
        self.countdown_timer.stop()
        self.btn_auto.setText("ü§ñ –ê–í–¢–û")
        self.signals.status.emit("‚ö™ –ì–û–¢–û–í")
        self.signals.volume.emit(0)

    def update_countdown(self):
        self.auto_seconds_left -= 1
        if self.auto_seconds_left < 0:
            try:
                self.auto_seconds_left = int(self.auto_interval_input.text()) - 1
            except:
                self.auto_seconds_left = 14
        self.signals.btn_auto_text.emit(f"ü§ñ –ê–í–¢–û ({self.auto_seconds_left}s)")

    def audio_engine(self, use_mic=False):
        try:
            if not self.whisper_model:
                self.signals.log.emit("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper...")
                self.whisper_model = WhisperModel(self.whisper_input.text(), device="cpu", compute_type="int8")

            p = pyaudio.PyAudio()
            if use_mic:
                device_info = p.get_default_input_device_info()
            else:
                wasapi_info = p.get_host_api_info_by_type(pyaudio.paWASAPI)
                device_info = p.get_device_info_by_index(wasapi_info["defaultOutputDevice"])
                if not device_info["isLoopbackDevice"]:
                    for loopback in p.get_loopback_device_info_generator():
                        if device_info["name"] in loopback["name"]:
                            device_info = loopback
                            break

            samplerate = int(device_info["defaultSampleRate"])
            channels = device_info["maxInputChannels"]

            stream = p.open(
                format=pyaudio.paInt16,
                channels=channels,
                rate=samplerate,
                input=True,
                input_device_index=device_info["index"],
                frames_per_buffer=1024
            )

            audio_buffer = []
            analyze_frames = int(samplerate / 1024 * 3)

            while self.is_running:
                data = stream.read(1024, exception_on_overflow=False)

                # –†–∞—Å—á–µ—Ç –≥—Ä–æ–º–∫–æ—Å—Ç–∏ (RMS/–ü–∏–∫)
                audio_data = np.frombuffer(data, dtype=np.int16)
                peak = np.abs(audio_data).max()
                normalized_vol = min(100, int((peak / 20000) * 100))
                self.signals.volume.emit(normalized_vol)

                audio_buffer.append(data)

                if len(audio_buffer) >= analyze_frames:
                    raw_audio = b"".join(audio_buffer)
                    audio_np = np.frombuffer(raw_audio, dtype=np.int16).astype(np.float32)
                    if channels > 1: audio_np = audio_np.reshape(-1, channels).mean(axis=1)
                    audio_np /= 32768.0

                    if samplerate != 16000:
                        audio_np = np.interp(
                            np.linspace(0, len(audio_np), int(len(audio_np) * 16000 / samplerate)),
                            np.arange(len(audio_np)), audio_np
                        )

                    if np.max(np.abs(audio_np)) > 0.02:
                        segments, _ = self.whisper_model.transcribe(audio_np, language="ru")
                        for s in segments:
                            txt = self.filter_text(s.text)
                            if txt:
                                self.accumulated_text += " " + txt
                                self.signals.log.emit(f"üé§ {txt}")
                    audio_buffer = []

            stream.stop_stream()
            stream.close()
            p.terminate()
        except Exception as e:
            self.signals.log.emit(f"üö® Audio Error: {e}")

    def trigger_ai_send(self):
        text = self.accumulated_text.strip()
        if text:
            self.signals.log.emit("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ AI...")
            threading.Thread(target=self.ask_ai, args=(text,), daemon=True).start()
            self.accumulated_text = ""
        elif not self.is_running and self.mic_mode:
            self.signals.status.emit("‚ö™ –ì–û–¢–û–í")

    def ask_ai(self, text, image_b64=None):
        token = self.token_input.text().strip()
        if not token: return
        content = [{"type": "text", "text": text}]
        if image_b64:
            content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}})
        try:
            r = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"},
                json={
                    "model": "google/gemini-2.0-flash-001",
                    "messages": [
                        {"role": "system", "content": self.prompt_edit.toPlainText()},
                        {"role": "user", "content": content}
                    ]
                }, timeout=40
            )
            if r.status_code == 200:
                ans = r.json()["choices"][0]["message"]["content"]
                self.signals.text.emit(ans)
        except Exception as e:
            self.signals.log.emit(f"üåê AI Error: {e}")

    def send_manual_text(self):
        t = self.input.text()
        if t:
            self.input.clear()
            threading.Thread(target=self.ask_ai, args=(t,), daemon=True).start()

    def take_screenshot(self):
        try:
            self.signals.log.emit("üì∏ –ê–Ω–∞–ª–∏–∑ —ç–∫—Ä–∞–Ω–∞...")
            img = ImageGrab.grab()
            buf = BytesIO()
            img.save(buf, format="JPEG", quality=70)
            img_str = base64.b64encode(buf.getvalue()).decode('utf-8')
            threading.Thread(target=self.ask_ai, args=("–†–µ—à–∏ –∑–∞–¥–∞—á—É —Å —ç–∫—Ä–∞–Ω–∞", img_str), daemon=True).start()
        except Exception as e:
            self.signals.log.emit(f"üì∏ Screen Error: {e}")


if __name__ == "__main__":
    app = QApplication(sys.argv)
    app.setStyle("Fusion")
    win = InterviewAssistantWin()
    win.show()
    sys.exit(app.exec())